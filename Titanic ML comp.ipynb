{"cells":[{"cell_type":"markdown","source":["Titanic - Machine learning from Disaster\r\n","\r\n","This is my first attempt at a Kaggle competition. This is a continuous project where I update and add code as I learn more data analysis/ML principles"],"metadata":{}},{"cell_type":"markdown","source":["Below are all of my imported libraries I use for DA/ML as well as loading in the training data and test data."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sb\r\n","from sklearn.model_selection import train_test_split, GridSearchCV\r\n","from sklearn.ensemble import RandomForestClassifier\r\n","from sklearn.ensemble import GradientBoostingClassifier\r\n","from sklearn.model_selection import cross_val_score\r\n","from sklearn.metrics import make_scorer\r\n","from sklearn.metrics import ConfusionMatrixDisplay\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","\r\n","train_data = pd.read_csv(r\"C:\\Users\\Dillon Rainwater\\Documents\\Python\\Kaggle Competitions\\Titanic\\titanic data\\train.csv\")\r\n","test_data = pd.read_csv(r\"C:\\Users\\Dillon Rainwater\\Documents\\Python\\Kaggle Competitions\\Titanic\\titanic data\\test.csv\")\r\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Below is a quick exploratory data analysis (EDA). Since most of the important features are categorical, simple bar graphs are quite effective at gaining insights on how features are correlated."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["train_data.head()\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["num_rows = len(train_data)\r\n","num_rows\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#finding missing values\r\n","missing_data_train = train_data.isna().sum()\r\n","missing_data_train = missing_data_train[missing_data_train > 0]\r\n","missing_data_train\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["missing_data_test = test_data.isna().sum()\r\n","missing_data_test = missing_data_test[missing_data_test > 0]\r\n","missing_data_test\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["survived_data = train_data.loc[train_data['Survived'] == 1]\r\n","survived_data.mean(skipna=True)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["died_data = train_data.loc[train_data['Survived'] == 0]\r\n","died_data.mean(skipna=True)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.barplot(x=\"Sex\", y=\"Survived\", data=train_data)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.barplot(x='Survived', y='Fare', data=train_data)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.barplot(x='Pclass', y='Survived', data=train_data)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.barplot(x='Pclass', y='Fare', data=train_data)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.barplot(x='Embarked', y='Survived', data=train_data)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.barplot(x=\"Embarked\", y='Fare', data=train_data)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.barplot(x='Survived', y='Fare', hue='Sex', data=train_data)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.barplot(x='Pclass', y='Fare', hue='Survived', data=train_data)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["g = sb.FacetGrid(data=train_data, row=\"Pclass\", col=\"Sex\", margin_titles=True)\r\n","g.map(sb.barplot, \"Survived\", \"Fare\")\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["for i, col in enumerate(['SibSp', 'Parch']):\r\n","    plt.figure(i)\r\n","    sb.catplot(x = col, y = 'Survived', data = train_data, kind = 'point')\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["g = sb.FacetGrid(data=train_data, col=\"Survived\", margin_titles=True)\r\n","g.map(sb.histplot, \"Age\")\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sb.heatmap(train_data.corr(), annot = True)\r\n","plt.title('Correlation between Features in train_data')\r\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Below I delete the few rows where there was no data in 'Emabarked' and 'Fare'.\r\n","I impute the 'Age' feature to replace empty values with the average age.\r\n","\r\n","Rather than having 'Cabin' as a feature with many different unique values, I created a feature 'cabin _missing' that indicates whether or not there was a cabin recoreded for the passenger. The barplot of 'cabin_missing' shows that there is some correlation between having a cabin and surviving."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Dealing with missing values\r\n","train_data['cabin_missing'] = np.where(train_data['Cabin'].isnull(), 1, 0)\r\n","sb.barplot(x='cabin_missing', y='Survived', data=train_data)\r\n","train_data['Age'].fillna(train_data['Age'].mean(), inplace = True)\r\n","train_data.drop(train_data.loc[train_data['Embarked'].isna() == True].index, inplace=True)\r\n","\r\n","# apply to test_data as well\r\n","test_data['cabin_missing'] = np.where(test_data['Cabin'].isnull(), 1, 0)\r\n","test_data['Age'].fillna(test_data['Age'].mean(), inplace = True)\r\n","\r\n","test_data.drop(test_data.loc[test_data['Fare'].isna() == True].index, inplace=True)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Here I set up my features for training my models. I also split my data into test and training sets.\r\n","\r\n","I use pd.get_dummies to convert the categorical features to numerical ones and I also normalize the data to a range of [0,1]"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["y = train_data[\"Survived\"]\r\n","\r\n","features = [\"Pclass\", \"Sex\", \"Fare\", \"Embarked\", \"cabin_missing\", \"Age\", 'SibSp', 'Parch']\r\n","X = pd.get_dummies(train_data[features])\r\n","X_test_data = pd.get_dummies(test_data[features])\r\n","\r\n","X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state = 0)\r\n","\r\n","# normalizing data\r\n","norm = MinMaxScaler().fit(X_train)\r\n","X_train_norm = norm.transform(X_train)\r\n","X_test_norm = norm.transform(X_test)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Below I created a function for finding the accuaracy score of the model given a specific n_estimators. However, this only tests one parameter of the model and I quickly found a better way to test paramaters using GridsearchCV\r\n","\r\n","I chose a couple of classifiers (Random Forest and Gradient Boosting) to test since we are trying to classify if a paseenger has 'survived' or 'not survived'"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["def get_RandomForest_scores(n_estimators):\r\n","    model = RandomForestClassifier(n_estimators=n_estimators, random_state=0, n_jobs=4)\r\n","    scores = cross_val_score(model, X, y, cv=5)\r\n","    return(scores)\r\n","\r\n","for n in [5,10,50,100,250,500]:\r\n","    print(get_RandomForest_scores(n))\r\n","    print(get_RandomForest_scores(n).mean())\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["def get_GradientBossting_scores(n_estimators):\r\n","    model = GradientBoostingClassifier(n_estimators=n_estimators, random_state=0)\r\n","    scores = cross_val_score(model, X, y, cv=5)\r\n","    return(scores)\r\n","\r\n","for n in [5,10,50,100,250,500]:\r\n","    print(get_GradientBossting_scores(n))\r\n","    print(get_GradientBossting_scores(n).mean())\r\n","\r\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Below I use GridSearchCV to to test multiple hyper parameters and highlight the best ones based on the default scorer (accuracy score)."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Using GridSearchCV to find best hyperparameters\r\n","\r\n","rf = RandomForestClassifier(n_jobs = -1, random_state = 0)\r\n","params = {\r\n","    'n_estimators': [5, 50, 100, 250],\r\n","    'max_depth': [2, 4, 8, 16, 32, None]\r\n","}\r\n","\r\n","cv = GridSearchCV(rf, params, cv = 5, n_jobs = -1)\r\n","cv.fit(X_train_norm, Y_train)\r\n","cv.best_params_\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["\r\n","gb = GradientBoostingClassifier(random_state = 0)\r\n","params = {\r\n","    'n_estimators': [5, 50, 100, 250],\r\n","    'max_depth': [2, 4, 8, 16, 32, None],\r\n","    'learning_rate': [0.01, 0.1, 1, 10, 100]\r\n","}\r\n","\r\n","cv = GridSearchCV(gb, params, cv = 5, n_jobs = -1)\r\n","cv.fit(X_train_norm, Y_train)\r\n","cv.best_params_\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model = RandomForestClassifier(n_estimators=250, max_depth=8, random_state=0)\r\n","model.fit(X_train_norm, Y_train)\r\n","score = model.score(X_train_norm, Y_train)\r\n","print(score)\r\n","rf_predictions = model.predict(X_test_norm)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model = GradientBoostingClassifier(learning_rate=0.1, max_depth=4, n_estimators=50)\r\n","model.fit(X_train_norm, Y_train)\r\n","score = model.score(X_train_norm, Y_train)\r\n","print(score)\r\n","gb_predictions = model.predict(X_test_norm)\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cm = confusion_matrix(Y_test, rf_predictions)\r\n","cm_display = ConfusionMatrixDisplay(cm)\r\n","cm_display.plot()\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cm = confusion_matrix(Y_test, gb_predictions)\r\n","cm_display = ConfusionMatrixDisplay(cm)\r\n","cm_display.plot()\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#predictions output to submission file\r\n","output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': rf_predictions})\r\n","output.to_csv('titanic_submission.csv', index=False)\r\n"],"outputs":[],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}